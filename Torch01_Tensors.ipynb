{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf829a2",
   "metadata": {},
   "source": [
    "# Chapter 1: Tensors\n",
    "Tensors are specialized data structures that are similar to arrays and matrices. In PyTorch, tensors encode the inputs and outputs of a model, as well as the model parameters. Tensors are similar to NumPy's ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and ndarrays often share the same underlying memory, eleminating the need to copy data. Tensors are also optimized for automatic dfferentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80d6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b604c89",
   "metadata": {},
   "source": [
    "## Initializing a Tensor:\n",
    "Tensors can be initialized in a few ways:\n",
    "\n",
    "### Directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba3373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f600329",
   "metadata": {},
   "source": [
    "### From a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a80e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ab42e",
   "metadata": {},
   "source": [
    "### From other tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4b0737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "Random Tensor: \n",
      "tensor([[0.5785, 0.2482],\n",
      "        [0.5302, 0.7312]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print (f\"Ones Tensor: \\n{x_ones}\\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print (f\"Random Tensor: \\n{x_rand}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46f43f",
   "metadata": {},
   "source": [
    "### With random or constant values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a97407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.8644, 0.7816, 0.9133],\n",
      "        [0.1851, 0.5820, 0.6776]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n",
      "Random Tensor with coded dimensions: \n",
      " tensor([[0.2984, 0.7033, 0.9322],\n",
      "        [0.4519, 0.9465, 0.1460]]) \n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,) # a tuple with dimensions for initializing tensors\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "rand_tensor_alt = torch.rand((2,3,), dtype=torch.float)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")\n",
    "print(f\"Random Tensor with coded dimensions: \\n {rand_tensor_alt} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e6f09",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor:\n",
    "Tensor attributes describe their shape, datatype, and the device they are located on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1326fc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the tensor: torch.Size([3, 4]).\n",
      "Data-type of the tensor: torch.float32.\n",
      "Device of the tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((3,4))\n",
    "\n",
    "print (f\"Shape of the tensor: {tensor.shape}.\")\n",
    "print (f\"Data-type of the tensor: {tensor.dtype}.\")\n",
    "print (f\"Device of the tensor: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d7b99",
   "metadata": {},
   "source": [
    "## Operations on a Tensor:\n",
    "There are over 100 tensor opperations ranging from arithmatic, to linear algebra, to matrix manipulations, sampling and more. The PyTorch website provides a comprehensive list of available operations [here](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "Each of the operations can be run on a GPU (typically faster than running on a CPU). By default, tensors are created on CPUs, and need to be explicitly moved to a GPU using the `.to` method. However, GPU memory being typically smaller than available memory, keep in mind that copying large tensors over may be computationally too expensive to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cc85c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the tensor: torch.Size([3, 4]).\n",
      "Data-type of the tensor: torch.float32.\n",
      "Device of the tensor: cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print (f\"Shape of the tensor: {tensor.shape}.\")\n",
    "print (f\"Data-type of the tensor: {tensor.dtype}.\")\n",
    "print (f\"Device of the tensor: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e21c8",
   "metadata": {},
   "source": [
    "### Most standard NumPy operations are available:\n",
    "\n",
    "### Indexing and slicing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71840cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.]).\n",
      "First column: tensor([1., 1., 1., 1.]).\n",
      "Last column: tensor([1., 1., 1., 1.]).\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "\n",
    "print (f\"First row: {tensor[0]}.\")\n",
    "print (f\"First column: {tensor[:,0]}.\")\n",
    "print (f\"Last column: {tensor[...,-1]}.\")\n",
    "tensor[:,1] = 0\n",
    "print (tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c569fa8",
   "metadata": {},
   "source": [
    "### Joining tensors:\n",
    "It is also possible to join two tensors with the `torch.cat` method along a given dimension. An alternative method to join tensors is the `torch.stack` method combining tensors along a **new** dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686b9e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined tensor (cat, dim=0): torch.Size([6, 2])\n",
      "Shape of combined tensor (cat, dim=1): torch.Size([2, 6])\n",
      "Shape of combined tensor (stack, dim = 0): torch.Size([3, 2, 2])\n",
      "Shape of combined tensor (stack, dim = 1): torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.ones((2,2))\n",
    "tensor_2 = torch.zeros((2,2))\n",
    "tensor_3 = torch.rand((2,2))\n",
    "\n",
    "# torch.cat concatenates tensors along existing dimensions\n",
    "tensor_cat_0 = torch.cat((tensor_1, tensor_2, tensor_3), dim = 0)\n",
    "print (f\"Shape of combined tensor (cat, dim=0): {tensor_cat_0.shape}\")\n",
    "\n",
    "# defining dimensions allows concatenation along different directions\n",
    "tensor_cat_1 = torch.cat((tensor_1, tensor_2, tensor_3), dim = 1)\n",
    "print (f\"Shape of combined tensor (cat, dim=1): {tensor_cat_1.shape}\")\n",
    "\n",
    "# torch.stack concatenates tensors along a new dimension\n",
    "tensor_stack_0 = torch.stack((tensor_1, tensor_2, tensor_3), dim = 0)\n",
    "print (f\"Shape of combined tensor (stack, dim = 0): {tensor_stack_0.shape}\")\n",
    "\n",
    "# defining dimensions stacks tensors along a different direction in the new tensor\n",
    "tensor_stack_1 = torch.stack((tensor_1, tensor_2, tensor_3), dim = 1)\n",
    "print (f\"Shape of combined tensor (stack, dim = 1): {tensor_stack_1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd8900",
   "metadata": {},
   "source": [
    "### Arithmatic operations:\n",
    "Matrix multiplications can be done in several ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeac6269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out = y3)\n",
    "\n",
    "\n",
    "y4 = torch.einsum('ij, kj-> ik', tensor, tensor)\n",
    "print (y1)\n",
    "print (y4)\n",
    "\n",
    "assert torch.equal(y1,y2) and torch.equal(y2,y3) and torch.equal(y3,y4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed37e5",
   "metadata": {},
   "source": [
    "### Single-element tensors:\n",
    "With a one-element tensor, like ones gotten from aggregating all values of a tensor, one can convert it into a Python numerical value using `item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbce731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print (agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d7fd8",
   "metadata": {},
   "source": [
    "### In-place operations:\n",
    "Operations that store the result into the operand are called in-place. They are denoted by a `_` suffix. For example `x.copy_(y)` or `x.t_()` makes changes to `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedfde72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: \n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]).\n",
      "\n",
      "Augmented tensor: \n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]]).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Original tensor: \\n{tensor}.\\n\")\n",
    "tensor.add_(5)\n",
    "print (f\"Augmented tensor: \\n{tensor}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82621f00",
   "metadata": {},
   "source": [
    "## Bridge with NumPy:\n",
    "Tensors on the **CPU** and NumPy arrays share their underlying memory locations, and changing one will change the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ff26af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: \n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "\n",
      "n: \n",
      "[1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print (f\"t: \\n{t}\\n\")\n",
    "n = t.numpy()\n",
    "print (f\"n: \\n{n}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb77192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: \n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "\n",
      "n: \n",
      "[3. 3. 3. 3. 3.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.add_(2)\n",
    "\n",
    "print (f\"t: \\n{t}\\n\")\n",
    "print (f\"n: \\n{n}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec84faf1",
   "metadata": {},
   "source": [
    "### This also works the othr way around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02984296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: \n",
      "[1. 1. 1.]\n",
      "\n",
      "t: \n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n",
      "\n",
      "n: \n",
      "[2. 2. 2.]\n",
      "\n",
      "t: \n",
      "tensor([2., 2., 2.], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(3)\n",
    "print (f\"n: \\n{n}\\n\")\n",
    "\n",
    "t = torch.from_numpy(n)\n",
    "print (f\"t: \\n{t}\\n\")\n",
    "\n",
    "np.add(n, 1, out=n)\n",
    "print (f\"n: \\n{n}\\n\")\n",
    "print (f\"t: \\n{t}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
